{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation datasets\n",
    "zone_1_training_data = pd.read_csv(\"seismic_zone_1.csv\")\n",
    "zone_1_val_data = pd.read_csv(\"seismic_zone_1_val.csv\")\n",
    "\n",
    "zone_2_training_data = pd.read_csv(\"seismic_zone_2.csv\")\n",
    "zone_2_val_data = pd.read_csv(\"seismic_zone_2_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for loading validation data\n",
    "FEATURES = [\"depth\", \"mag\", \"gap\", \"dmin\", \"rms\"]\n",
    "def load_val_data(df):\n",
    "    X_test = df[FEATURES] \n",
    "    y_true = df[[\"latitude\", \"longitude\"]]\n",
    "    \n",
    "    return X_test, y_true\n",
    "\n",
    "# API calls\n",
    "def predict(url, X_test):\n",
    "    API_URL = f'{url}/predict'\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for _, row in X_test.iterrows():\n",
    "        payload = row.to_dict()\n",
    "        \n",
    "        response = requests.post(API_URL, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            pred = response.json()[\"prediction\"]\n",
    "            predictions.append(pred[0])\n",
    "        else:\n",
    "            print(f\"Error for input {row}: {response.text}\")\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate_predictions(model_response, true_value):\n",
    "    y_pred = pd.DataFrame(model_response, columns=[\"latitude\", \"longitude\"])\n",
    "    \n",
    "    y_pred = pd.DataFrame(model_response, columns=[\"latitude\", \"longitude\"])\n",
    "    true_value = true_value.reset_index(drop=True)\n",
    "\n",
    "    mse_lat = mean_squared_error(true_value[\"latitude\"], y_pred[\"latitude\"])\n",
    "    mse_lon = mean_squared_error(true_value[\"longitude\"], y_pred[\"longitude\"])\n",
    "\n",
    "    r2_lat = r2_score(true_value[\"latitude\"], y_pred[\"latitude\"])\n",
    "    r2_lon = r2_score(true_value[\"longitude\"], y_pred[\"longitude\"])\n",
    "\n",
    "    mae_lat = mean_absolute_error(true_value[\"latitude\"], y_pred[\"latitude\"])\n",
    "    mae_lon = mean_absolute_error(true_value[\"longitude\"], y_pred[\"longitude\"])\n",
    "\n",
    "    print(f\"Mean Squared Error (Latitude): {mse_lat}\")\n",
    "    print(f\"Mean Squared Error (Longitude): {mse_lon}\\n\")\n",
    "\n",
    "    print(f\"R² Score (Latitude): {r2_lat}\")\n",
    "    print(f\"R² Score (Longitude): {r2_lon}\\n\")\n",
    "\n",
    "    print(f\"Mean Absolute Error (Latitude): {mae_lat}\")\n",
    "    print(f\"Mean Absolute Error (Longitude): {mae_lon}\")\n",
    "    \n",
    "def retrain(url, df, save_as=\"updated_model.pkl\"):\n",
    "    API_URL = f'{url}/retrain'\n",
    "    \n",
    "    data_payload = {\n",
    "        \"features\": df[[\"depth\", \"mag\", \"gap\", \"dmin\", \"rms\"]].to_dict(orient=\"records\"),\n",
    "        \"latitude\": df[\"latitude\"].tolist(),\n",
    "        \"longitude\": df[\"longitude\"].tolist()\n",
    "    }\n",
    "\n",
    "    params = {\"save_as\": save_as}\n",
    "    response = requests.post(API_URL, params=params, json=data_payload)\n",
    "    print(response.json())\n",
    "    \n",
    "def list_models(url):\n",
    "    print(requests.get(f'{url}/list_models').json())\n",
    "    \n",
    "def reload_model(url, model_name):\n",
    "    API_URL = f'{url}/reload_model'\n",
    "    params = {\"model_name\": model_name}\n",
    "\n",
    "    response = requests.post(API_URL, params=params)\n",
    "    print(response.json())\n",
    "    \n",
    "def download_model(url, model_name):\n",
    "    API_URL = f'{url}/download_model'\n",
    "    params = {\"model_name\": model_name}\n",
    "    \n",
    "    response = requests.get(API_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(model_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"✅ {model_name} downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to download {model_name}. Error: {response.json()}\")\n",
    "    \n",
    "def upload_model(url, model_file):\n",
    "    API_URL = f'{url}/upload_model'\n",
    "\n",
    "    with open(model_file, \"rb\") as file:\n",
    "        response = requests.post(API_URL, files={\"file\": file})\n",
    "        \n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zone 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1_API = \"https://fedml.onrender.com\"\n",
    "X_1, y_1 = load_val_data(zone_1_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved_models': ['zone_0_model.pkl']}\n"
     ]
    }
   ],
   "source": [
    "list_models(zone1_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(zone1_API, X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Latitude): 55.6867846556177\n",
      "Mean Squared Error (Longitude): 22.85913167833489\n",
      "\n",
      "R² Score (Latitude): -5.6006510125206415\n",
      "R² Score (Longitude): -21.468817233732548\n",
      "\n",
      "Mean Absolute Error (Latitude): 6.683537563025212\n",
      "Mean Absolute Error (Longitude): 4.655139546218472\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(predictions, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model retrained and saved as zone_0_zone_1_model.pkl.'}\n"
     ]
    }
   ],
   "source": [
    "retrain(zone1_API, zone_1_training_data, 'zone_0_zone_1_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved_models': ['zone_0_model.pkl', 'zone_0_zone_1_model.pkl']}\n"
     ]
    }
   ],
   "source": [
    "list_models(zone1_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': '✅ Model zone_0_zone_1_model.pkl successfully reloaded!'}\n"
     ]
    }
   ],
   "source": [
    "reload_model(zone1_API, 'zone_0_zone_1_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = predict(zone1_API, X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Latitude): 55.6867846556177\n",
      "Mean Squared Error (Longitude): 22.85913167833489\n",
      "\n",
      "R² Score (Latitude): -5.6006510125206415\n",
      "R² Score (Longitude): -21.468817233732548\n",
      "\n",
      "Mean Absolute Error (Latitude): 6.683537563025212\n",
      "Mean Absolute Error (Longitude): 4.655139546218472\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(predictions, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ zone_0_zone_1_model.pkl downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "download_model(zone1_API, 'zone_0_zone_1_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zone 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone2_API = \"https://fedml-zone2.onrender.com\"\n",
    "X_2, y_2 = load_val_data(zone_2_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved_models': ['zone_0_model.pkl']}\n"
     ]
    }
   ],
   "source": [
    "list_models(zone2_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = predict(zone2_API, X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Latitude): 8.581386455635915\n",
      "Mean Squared Error (Longitude): 1.419967758709142\n",
      "\n",
      "R² Score (Latitude): -12.975120181897791\n",
      "R² Score (Longitude): -0.03546827145377596\n",
      "\n",
      "Mean Absolute Error (Latitude): 2.598107553333334\n",
      "Mean Absolute Error (Longitude): 0.8375822466666637\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(predictions_2, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model retrained and saved as zone_0_zone2_model.pkl.'}\n"
     ]
    }
   ],
   "source": [
    "retrain(zone2_API, zone_2_training_data, \"zone_0_zone_2_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saved_models': ['zone_0_model.pkl', 'zone_0_zone2_model.pkl']}\n"
     ]
    }
   ],
   "source": [
    "list_models(zone2_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Model zone_0_zone_2_model.pkl not found!'}\n"
     ]
    }
   ],
   "source": [
    "reload_model(zone2_API, \"zone_0_zone_2_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = predict(zone2_API, X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Latitude): 0.28959644008745367\n",
      "Mean Squared Error (Longitude): 0.6505956206239898\n",
      "\n",
      "R² Score (Latitude): 0.5283809818617452\n",
      "R² Score (Longitude): 0.5255729444763328\n",
      "\n",
      "Mean Absolute Error (Latitude): 0.36367409333333334\n",
      "Mean Absolute Error (Longitude): 0.4909193933333293\n"
     ]
    }
   ],
   "source": [
    "evaluate_predictions(predictions_2, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to download zone_0_zone_2_model.pkl. Error: {'detail': 'Model not found'}\n"
     ]
    }
   ],
   "source": [
    "download_model(zone2_API, 'zone_0_zone_2_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation and Deployment of New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'zone0_zone1_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m zone_0_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzone_0_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m zone_1_model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzone0_zone1_model.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m zone_2_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzone0_zone2_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'zone0_zone1_model.pkl'"
     ]
    }
   ],
   "source": [
    "zone_0_model = joblib.load(\"zone_0_model.pkl\")\n",
    "zone_1_model = joblib.load(\"zone0_zone1_model.pkl\")\n",
    "zone_2_model = joblib.load(\"zone0_zone2_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated Decision Boundary Approximation completed. Model saved as federated_approx_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Extract decision boundary samples from a RandomForestRegressor.\n",
    "def extract_decision_data(model):\n",
    "    X_decision, y_decision = [], []\n",
    "    \n",
    "    for tree in model.estimators_:\n",
    "        tree_ = tree.tree_\n",
    "        features = tree_.feature\n",
    "        thresholds = tree_.threshold\n",
    "        values = tree_.value.squeeze()\n",
    "\n",
    "        for node in range(tree_.node_count):\n",
    "            if features[node] != -2:  # Not a leaf node\n",
    "                X_decision.append(features[node])\n",
    "                y_decision.append(thresholds[node])\n",
    "    \n",
    "    return np.array(X_decision).reshape(-1, 1), np.array(y_decision)\n",
    "\n",
    "# Generates a global model by learning from decision boundaries of all local models.\n",
    "def federated_decision_boundary_approximation(models):\n",
    "\n",
    "    all_X, all_y = [], []\n",
    "\n",
    "    for model in models:\n",
    "        X_decision, y_decision = extract_decision_data(model)\n",
    "        all_X.append(X_decision)\n",
    "        all_y.append(y_decision)\n",
    "\n",
    "    X_combined = np.vstack(all_X)\n",
    "    y_combined = np.hstack(all_y)\n",
    "\n",
    "    global_model = RandomForestRegressor(n_estimators=50)\n",
    "    global_model.fit(X_combined, y_combined)\n",
    "\n",
    "    return global_model\n",
    "\n",
    "zone_0_model = joblib.load(\"zone_0_model.pkl\")\n",
    "zone_1_model = joblib.load(\"zone_0_zone_1_model.pkl\")\n",
    "zone_2_model = joblib.load(\"zone_0_zone_2_model.pkl\")\n",
    "\n",
    "agg_model = federated_decision_boundary_approximation([zone_0_model, zone_1_model, zone_2_model])\n",
    "joblib.dump(agg_model, \"zone_0+1+2_model.pkl\")\n",
    "\n",
    "print(\"Federated Decision Boundary Approximation completed. Model saved as zone_0+1+2_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
